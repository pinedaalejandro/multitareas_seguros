{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c52b5c4",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "La compañía de seguros **Sure Tomorrow** quiere resolver varias tareas con la ayuda de machine learning y te pide que evalúes esa posibilidad.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- **Tarea 1**: encontrar clientes que sean similares a un cliente determinado. Esto ayudará a los agentes de la compañía con el marketing.\n",
    "- **Tarea 2**: predecir si es probable que un nuevo cliente reciba un beneficio de seguro. ¿Puede un modelo de predicción funcionar mejor que un modelo ficticio?\n",
    "- **Tarea 3**: predecir la cantidad de beneficios de seguro que probablemente recibirá un nuevo cliente utilizando un modelo de regresión lineal.\n",
    "- **Tarea 4**: proteger los datos personales de los clientes sin romper el modelo de la tarea anterior.\n",
    "\n",
    "# Preprocesamiento de información\n",
    "\n",
    "Importaremos la librerías necesarias a lo largo de este documento y evaluaremos la calidad de los datos proporcionados por la compañia `Sure Tomorrow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3bf372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb317a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Family members</th>\n",
       "      <th>Insurance benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>49700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>51700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age   Salary  Family members  Insurance benefits\n",
       "0       1  41.0  49600.0               1                   0\n",
       "1       0  46.0  38000.0               1                   1\n",
       "2       0  29.0  21000.0               0                   0\n",
       "3       0  21.0  41700.0               2                   0\n",
       "4       1  28.0  26100.0               0                   0\n",
       "5       1  43.0  41000.0               2                   1\n",
       "6       1  39.0  39700.0               2                   0\n",
       "7       1  25.0  38600.0               4                   0\n",
       "8       1  36.0  49700.0               1                   0\n",
       "9       1  32.0  51700.0               1                   0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando datos\n",
    "df = pd.read_csv('datasets/insurance_us.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d68072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Gender              5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   float64\n",
      " 2   Salary              5000 non-null   float64\n",
      " 3   Family members      5000 non-null   int64  \n",
      " 4   Insurance benefits  5000 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Información detallada de \"df\"\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1155bf",
   "metadata": {},
   "source": [
    "Lo único que podemos mejorar de esta información es el tipo de dato para las columnas `Age` y `Salary` pues son enteros y el nombre de las columnas pues si bien no son erroneos, por buenas prácticas estas deben ser completamente en minúsuculas, ademas de que en vez de contener espacios deben ser guiones bajos `_`. Por tal motivo procederemos con la corrección de dicha información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ce7581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   gender              5000 non-null   int64\n",
      " 1   age                 5000 non-null   int64\n",
      " 2   salary              5000 non-null   int64\n",
      " 3   family_members      5000 non-null   int64\n",
      " 4   insurance_benefits  5000 non-null   int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Renomabrando columnas de \"df\" y pasando los datos a valores \"int\"\n",
    "df.rename(columns={'Gender':'gender',\n",
    "                   'Age':'age',\n",
    "                   'Salary':'salary',\n",
    "                   'Family members':'family_members',\n",
    "                   'Insurance benefits':'insurance_benefits'},inplace=True)\n",
    "df = df.astype('int64')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d777d0b",
   "metadata": {},
   "source": [
    "Una vez contamos con la información adecuada en el formato correcto comenzaremos con los objetivos que solicita `Sure Tomorrow`.\n",
    "# Tarea \"1\": Encontrar clientes que sean similares a un cliente determinado. \n",
    "\n",
    "De acuerdo con lo que se solicita en la **Tarea 1** debemos trabajar con distancias, estas pueden ser `euclideana` o `manhattan`, por lo que la función contendra ambas métricas.\n",
    "\n",
    "Para poder demostrar este objetivo, crearemos la función `nearest_neighbor_predict` con la intención de que pueda determinar a que grupo puede pertenecer pero primero, debemos separar la variable objetivo del resto de datos, es decir, debemos aislar la columna `insurance_benefits` del resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc7c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construyendo la función \"nearest_neighbor_predict\"\n",
    "def nearest_neighbor_predict(clients,client,quantity):\n",
    "    \n",
    "    X = clients.drop(columns=['insurance_benefits']).values\n",
    "    y = np.array(client)\n",
    "    new_df = clients.copy()\n",
    "    \n",
    "    values_1 = []\n",
    "    values_2 = []\n",
    "    for idx in range(X.shape[0]):\n",
    "        values_1.append(euclidean(X[idx],y))\n",
    "        values_2.append(cityblock(X[idx],y))\n",
    "    \n",
    "    new_df['euclidean'] = pd.Series(values_1)\n",
    "    new_df['manhattan'] = pd.Series(values_2)\n",
    "    \n",
    "    result_1 = new_df.sort_values(by='euclidean',ascending=True)\n",
    "    result_2 = new_df.sort_values(by='manhattan',ascending=True)\n",
    "    \n",
    "    return result_1.iloc[:quantity,[0,1,2,3]], result_2.iloc[:quantity,[0,1,2,3]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4ec54",
   "metadata": {},
   "source": [
    "Esta función nos permite identificar aquellos clientes similares a al que estamos tomando como referencia, ademas que nos muestra la cantidad de clientes similares que se le indique. La función `nearest_neighbor_predict` permite hacer esta identificación a través de los siguientes parámetros:\n",
    "\n",
    "- `clients`: Es el `df` que contiene todos los clientes proporcionados por `Sure Tomorrow`. Tipo de dato `DataFrame`.\n",
    "- `client`: Es el registro que tomaremos como referencia para saber cuantos de los contenidos en `df` son similares. Tipo de dato `list`\n",
    "- `quantity`: La cantidad de clientes similares que nos interesan. Tipo de dato `int`.\n",
    "\n",
    "Ahora probaremos la función con el parámetro `client = [1,43,41000,2]` y buscaremos los `7` clientes más parecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf82796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      gender  age  salary  family_members\n",
       " 5          1   43   41000               2\n",
       " 1995       0   45   41000               0\n",
       " 3801       0   46   41000               2\n",
       " 3972       1   40   41000               1\n",
       " 4763       1   46   41000               1\n",
       " 2759       0   47   41000               3\n",
       " 2717       0   37   41000               0,\n",
       "       gender  age  salary  family_members\n",
       " 5          1   43   41000               2\n",
       " 3972       1   40   41000               1\n",
       " 3801       0   46   41000               2\n",
       " 4763       1   46   41000               1\n",
       " 1995       0   45   41000               0\n",
       " 2759       0   47   41000               3\n",
       " 3434       1   36   41000               2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando \"nearest_neighbor_predict\"\n",
    "a, b = nearest_neighbor_predict(df,[1,43,41000,2],7)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ace68",
   "metadata": {},
   "source": [
    "Como podemos observar en el resultado, tenemos vectores diferentes para cada una de las métricas de distancia calculadas que son similares al vector `client`, sin embargo también podemos observar que esto puede deberse a que hay una escala muy diferente entre los valores que toman las columnas resaltando la columna `salary` con el resto siendo la que tiene valores mucho más elevados que las demas por lo que ahora abordaremos el ejercicio aplicando un metodo de escalamiento haciendo uso de la función `Standard Scaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17bce01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      gender  age  salary  family_members\n",
       " 5          1   43   41000               2\n",
       " 1147       1   42   40800               2\n",
       " 4074       1   43   39600               2\n",
       " 1019       1   42   39600               2\n",
       " 2962       1   41   41100               2\n",
       " 2128       1   45   40500               2\n",
       " 106        1   45   41600               2,\n",
       "       gender  age  salary  family_members\n",
       " 5          1   43   41000               2\n",
       " 1147       1   42   40800               2\n",
       " 4074       1   43   39600               2\n",
       " 2962       1   41   41100               2\n",
       " 1019       1   42   39600               2\n",
       " 2128       1   45   40500               2\n",
       " 106        1   45   41600               2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construyendo la función \"nearest_neighbor_predict\" aplicando escalamiento a \"df\"\n",
    "def nearest_neighbor_predict(clients,client,quantity):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    clients = clients.drop(columns=['insurance_benefits']).values\n",
    "\n",
    "    scaler.fit(clients)\n",
    "    X = scaler.transform(clients)\n",
    "    client = scaler.transform(np.array(client).reshape(1,-1))\n",
    "    y = client[0]\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    values_1 = []\n",
    "    values_2 = []\n",
    "    for idx in range(X.shape[0]):\n",
    "        values_1.append(euclidean(X[idx],y))\n",
    "        values_2.append(cityblock(X[idx],y))\n",
    "    \n",
    "    new_df['euclidean'] = pd.Series(values_1)\n",
    "    new_df['manhattan'] = pd.Series(values_2)\n",
    "    \n",
    "    result_1 = new_df.sort_values(by='euclidean',ascending=True)\n",
    "    result_2 = new_df.sort_values(by='manhattan',ascending=True)\n",
    "    \n",
    "    return result_1.iloc[:quantity,[0,1,2,3]], result_2.iloc[:quantity,[0,1,2,3]]\n",
    "\n",
    "a, b = nearest_neighbor_predict(df,[1,43,41000,2],7)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09890296",
   "metadata": {},
   "source": [
    "Aplicando el cálculo de distancia `euclidiana` y `manhattan` al escalamiento de los datos podemos observar que los registros son considerablemente más similares variando un poco en la columna `salary` mientras que en el resto son practicaménte iguales por lo que podemos concluir que hacer uso de escalamiento debe ser considerado si tenemos una diferencia considerable entre los datos que recibe cada columna.\n",
    "\n",
    "# Tarea 2: Predecir si es probable que un nuevo cliente reciba un beneficio de seguro. \n",
    "\n",
    "¿Puede un modelo de predicción funcionar mejor que un modelo ficticio?. Un modelo de predicción intentaría predecir el mejor resultado mientras que un modelo ficticio es también conocido como el modelo `dummy` que es un código simple que no significa nada.\n",
    "\n",
    "Comenzaremos explicando de que se trata la `regresión lineal` que es un modelo matemático con el objetivo de poder encontrar la línea recta que mejor se ajuste a los datos que le estamos proporcionando, es decir, buscara un ajuste que le permita tener la pendiente y posición más adecuadas en el plano que minimice totalmente el error que pueda proporcionar al predecir algún parámetro. Esta función está basada en la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "a = (X \\cdot w) + w_0\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- X: Contiene la matriz de datos correspondiente de la información proporcionada en `df`.\n",
    "- w: Cotiene un vector de pesos que permitirá que la la recta ajuste su pendiente.\n",
    "- w0: Cotiene el ajuste de altura que dicha recta tendra a lo largo de sus ejes.\n",
    "\n",
    "Comenzaremos con la creación del modelo `dummy` y evaluaremos su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e171a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando la clase \"dummy_regression\"\n",
    "class dummy_regression():\n",
    "    def fit(self,train_features,train_target):\n",
    "        self.train_features = train_features\n",
    "        self.train_target = train_target\n",
    "    def predict(self,test_features):\n",
    "        return np.zeros(test_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1d4ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: -0.1021184544233924\n"
     ]
    }
   ],
   "source": [
    "# Verificando funcionamiento de \"dummy_regression\"\n",
    "features = df.drop(columns=['insurance_benefits'],axis=1)\n",
    "target = df['insurance_benefits']\n",
    "\n",
    "model = dummy_regression()\n",
    "model.fit(features,target)\n",
    "predictions = model.predict(features)\n",
    "print('r2_score:',r2_score(target,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68f53b",
   "metadata": {},
   "source": [
    "Como podemos ver, un modelo ficticio nos arroja un resultado negativo en la evaluación, esto nos indica que el ajuste de la recta que es capaz de modelar basado en los datos que le proporcionamos no esta ni cerca de ser el mejor ajuste para predecir de forma eficiente. Ahora crearemos la función `linear_regressión` para verificar si este modelo logra tener un mejor rendimiento que el ficticio.\n",
    "\n",
    "Basados en la formula presentada al inicio de esta sección y al trabajar con vectores en vez de valores escalares, debemos trabajar dichos vectores mejor conocidos como `matrices`. Nuestra matriz de datos es aquella que contiene toda la información referente a nuestras características, es decir lo que guardamos en la variable `features` que analogo a la fórmula es `X`. Por otro lado tenemos a `w` que es un vector de pesos, estos pesos no son tán fáciles de encontrar pues deben ser de acuerdo a la información proporcionada por `features` que matematicamente estaría dado por la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "Por lo que debemos trabajar con matrices transpuestas e inversas. Afortunadamente todas estos procesos podemos encontrarlos en python por lo que construiremos la clase y procederemos a evaluarla de la misma manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4769c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression():\n",
    "    def fit(self,train_features,train_target):\n",
    "        X = np.concatenate((np.ones((train_features.shape[0], 1)), train_features), axis=1)\n",
    "        y = train_target\n",
    "        w = (np.linalg.inv(X.T.dot(X)).dot(X.T)).dot(y)\n",
    "        self.w = w[1:]\n",
    "        self.w0 = w[0]\n",
    "\n",
    "    def predict(self, test_features):\n",
    "        return test_features.dot(self.w) + self.w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "507fdf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.42494550308169177\n"
     ]
    }
   ],
   "source": [
    "# Verificando funcionamiento de \"dummy_regression\"\n",
    "model = linear_regression()\n",
    "model.fit(features,target)\n",
    "predictions = model.predict(features)\n",
    "print('r2_score:',r2_score(target,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce29b41",
   "metadata": {},
   "source": [
    "Como podemos observar si bien no tenemos el mejor ajuste, este modelo tiene la capacidad de predecir con mejor precisión que el modelo ficticio por lo que contestanto a la pregunta:\n",
    "\n",
    "- **¿Puede un modelo de predicción funcionar mejor que un modelo ficticio?**\n",
    "\n",
    "Esto es lógico puesto que de forma matemática cumplimos con todos los parámetros de la formula de `regresión lineal` que se acompla una una `regresión líneal múltiple` que es aquella que trabaja con matrices y no valores escalares lo que nos permite poder considerar más de una característica de nustros datos y poder modelar una línea en un hiperplano.\n",
    "\n",
    "# Tarea 3: Predecir la cantidad de beneficios de seguro que probablemente recibirá un nuevo cliente utilizando un modelo de regresión lineal.\n",
    "\n",
    "Ahora probaremos los modelos anteriores contra los modelos de regresión lineal que nos propociona `scikit learn` con la intención de evaluar nuevamente el rendimiento que estos nos proporcionan en su forma más básica, es decir, con los hiperparámetros ajustados a los valores por default.\n",
    "\n",
    "## Regresión lineal\n",
    "\n",
    "Comenzaremos con el más básico que es la `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3415f405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenando modelo\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(features,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388865d",
   "metadata": {},
   "source": [
    "Prodeceremos con la evaluación de `lr_model` para la cuál aplicaremos la validación cruzada para esto con la intención de obtener un mejor parámetro de desempeño al cambiar los bloques de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45a03820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempeño: 0.42311376920775334\n"
     ]
    }
   ],
   "source": [
    "# Evaluando con validación cruzada\n",
    "score = cross_val_score(lr_model,features,target,cv=5)\n",
    "print('Desempeño:',np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7401ae",
   "metadata": {},
   "source": [
    "De acuerdo con los valores que arroja de desempeño tanto la `regresión lineal` de `sklearn` como la implementada en la clase `linear_regression` son muy similares, sin embargo, `linear_regression` es un poco más precisa pues tiene un `score` ligeramente más elevado.\n",
    "\n",
    "## Árboles de decisión\n",
    "\n",
    "Continuaremos ahora con el modelo `DecisionTreeRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5018711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=12345)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenando modelo\n",
    "dtr_model = DecisionTreeRegressor(random_state=12345)\n",
    "dtr_model.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7539ec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempeño: 0.9954002737197343\n"
     ]
    }
   ],
   "source": [
    "# Evaluando con validación cruzada\n",
    "score = cross_val_score(dtr_model,features,target,cv=5)\n",
    "print('Desempeño:',np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f7e86e",
   "metadata": {},
   "source": [
    "Observamos una gran diferencia entre el desempeño de los modelos de regresión tradicionales y la `regresión de árboles de decisión` pues esta tiene un desempeño considerablemente superior.\n",
    "\n",
    "## Bosques aleatorios\n",
    "\n",
    "Por último probaremos el modelo de `RandomForestRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fec5bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=12345)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenando modelo\n",
    "rfr_model = RandomForestRegressor(random_state=12345)\n",
    "rfr_model.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdaf0e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempeño: 0.9974211669336996\n"
     ]
    }
   ],
   "source": [
    "# Evaluando con validación cruzada\n",
    "score = cross_val_score(rfr_model,features,target,cv=5)\n",
    "print('Desempeño:',np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc56314",
   "metadata": {},
   "source": [
    "Para finalizar, observamos que el desempeño de este modelo es ligeramente superior al anteriormente mencionado, por tal motivo, haremos uso de este modelo para predecir la cantidad de beneficios que un cliente nuevo puede recibir basado en el entrenamiento ya realizado. Para probar el modelo haremos uso del cliente propuesto en la tarea 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c17757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predicción de beneficios de un cliente nuevo\n",
    "prediction = rfr_model.predict([[1,43,41000,2]])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a580eb4c",
   "metadata": {},
   "source": [
    "Compararemos este resultado con el resultado proporcionado por la función `nearest_neighbor_predict` para verificar que este resultado sea lo más cercano al correcto posible comparando los beneficios con los que cuentan los cliente con mayor similitud al nuevo cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c0d4abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      gender  age  salary  family_members  insurance_benefits\n",
       " 5          1   43   41000               2                   1\n",
       " 1147       1   42   40800               2                   0\n",
       " 4074       1   43   39600               2                   1\n",
       " 1019       1   42   39600               2                   0\n",
       " 2962       1   41   41100               2                   0,\n",
       "       gender  age  salary  family_members  insurance_benefits\n",
       " 5          1   43   41000               2                   1\n",
       " 1147       1   42   40800               2                   0\n",
       " 4074       1   43   39600               2                   1\n",
       " 2962       1   41   41100               2                   0\n",
       " 1019       1   42   39600               2                   0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecutando \"nearest_neighbor_predict\"\n",
    "idx_1, idx_2 = nearest_neighbor_predict(df,[1,43,41000,2],5)\n",
    "df.iloc[idx_1.index,:], df.iloc[idx_2.index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352eced",
   "metadata": {},
   "source": [
    "De acuerdo con lo obtenido tanto de `nearest_neighbor_predict` como del modelo de regresión lineal, podemos observar congruencia en los resultados pues si bien tenemos un registro que es similar y que tiene un total de beneficios nulo, los 4 restantes tienen un beneficio lo que coincide con la predicción realizada anteriormente.\n",
    "\n",
    "Por último y con la intención de implementar seguridad al algoritmo, implementaremos lo que se conoce como `enmascaramiento` u `ofuscación` de datos que es un proceso que nos permite encriptar la información para que se dificulte su lectura y entendimiento a cualquier persona que no este autorizada de conocerla pero sin perder la eficiencia anteriormente mostrada en los algoritmos lo que nos lleva a la tarea final.\n",
    "\n",
    "# Tarea 4: Proteger los datos personales de los clientes sin romper el modelo de la tarea anterior.\n",
    "\n",
    "Para proteger los datos personales que se manejan en `df` podemos hacer uso de diferentes técnicas y considerar muchos puntos dependiendo de la necesidad y nivel de protección. Una de las bibliotecamos más conocidas en python para poder llevar a cabo este proceso es `cryptography.fernet` que es una clase que nos permite hacer la encriptación y desencriptación haciendo uso de una llave o mejor conocido como `token`.\n",
    "\n",
    "Este método nos permite poder cifrar y descifrar la información a través del uso del mismo `token`, por lo que haremos uso de ella y probaremos el modelo de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d4c54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando le proceso de ofuscación\n",
    "import hashlib\n",
    "new_df = pd.DataFrame()\n",
    "for column in df.columns:\n",
    "    values = []\n",
    "    for val in df[column]:\n",
    "        hash_object = hashlib.sha256(str(val).encode('utf-8'))\n",
    "        hash_value = int(hash_object.hexdigest(),16) % 1000000\n",
    "        values.append(hash_value)\n",
    "    new_df[column] = values\n",
    "\n",
    "new_df.to_csv('datasets/insurance_us_ofuscated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b31ab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempeño: 0.9350936889580428\n"
     ]
    }
   ],
   "source": [
    "# Implementando el modelo de regresión lineal\n",
    "features = new_df.drop(columns=['insurance_benefits'],axis=1)\n",
    "target = new_df['insurance_benefits']\n",
    "new_rfr_model = RandomForestRegressor(random_state=12345)\n",
    "new_rfr_model.fit(features,target)\n",
    "score = cross_val_score(new_rfr_model,features,target,cv=5)\n",
    "print('Desempeño:',np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36b1f1",
   "metadata": {},
   "source": [
    "De acuerdo con el desempeño que el algoritmo de regresión lineal tiene una vez si aplico da `ofuscación` a los datos, vemos que sigue teniendo un desempeño elevado que si bien este se vió disminuido aproximadamente un `6%` esto es de entenderse debido a los datos de la `ofuscación` propician a un rendimiento un poco más bajo por la transformación que sufren los datos a lo largo de este proceso.\n",
    "\n",
    "# Conclusión\n",
    "\n",
    "De manera general se lograrón cumplir con las 4 tareas designadas por la compañia `Sure Tomorrow` en las que se pudo demostrar que podemos encontrar clientes con características similares a uno en específico ayudando a la compañia con campañas de marketing. Por otro lado pudimos verficiar que si hay clientes que tienen características similares a otros que ya hay recibido beneficios por parte del seguro, es probable que de igual forma reciban un beneficio aunque estos sean clientes nuevos.\n",
    "\n",
    "Al implementar un modelo de `regresión lineal` podemos de igual forma predecir la cantidad de beneficios que un cliente puede llegar a tener con precisión adecuada incluso aplicando `ofuscación` a los registros para que estos se encuentren protegidos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
